{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install split-folders","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#CREATE DIRECTORIES\nimport os\nimport shutil\n\n\nworking_dir = './training'\nif(os.path.isdir(working_dir)):\n    shutil.rmtree(working_dir)\nos.mkdir(working_dir)\nos.mkdir(os.path.join(working_dir, 'NO PERSON'))\nos.mkdir(os.path.join(working_dir, 'ALL THE PEOPLE'))\nos.mkdir(os.path.join(working_dir, 'SOMEONE'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#IMPORT STUFF + TEST JSON\nimport json\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom shutil import copy\nfrom PIL import Image\n\nwith open('../input/artificial-neural-networks-and-deep-learning-2020/MaskDataset/train_gt.json') as f:\n    labels = json.load(f) # crea dizionario in python\n    print(labels['14985.jpg'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dir = '/kaggle/input/artificial-neural-networks-and-deep-learning-2020/MaskDataset'\ntraining_dir = os.path.join(dataset_dir, 'training')\ntraining_dir\n\ndataset_dir = '/kaggle/input/artificial-neural-networks-and-deep-learning-2020/MaskDataset'\ntest_dir = os.path.join(dataset_dir, 'test')\ntest_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#COPY IMAGES IN RESPECTIVE FOLDERS\ndataset_dir = '/kaggle/input/artificial-neural-networks-and-deep-learning-2020/MaskDataset'\ntraining_dir = os.path.join(dataset_dir, 'training')\n\nfor dirname, _, filenames in os.walk(training_dir):\n    for filename in filenames:\n        if labels[filename] == 0:\n            copy(os.path.join(dirname, filename), os.path.join(working_dir, 'NO PERSON') )\n        elif labels[filename] == 1:\n            copy(os.path.join(dirname, filename), os.path.join(working_dir, 'ALL THE PEOPLE') )\n        elif labels[filename] == 2:\n            copy(os.path.join(dirname, filename), os.path.join(working_dir, 'SOMEONE') )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \n#import pandas as pd\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport os\nimport tensorflow as tf\nimport splitfolders\n\nSEED = 1234\nsplitfolders.ratio(working_dir, output=\"output\", seed=SEED, ratio=(0.85, 0.15), group_prefix=None)\ntf.random.set_seed(SEED)  \n\n# Get current working directory\ncwd = os.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\napply_data_augmentation = True\n\nif apply_data_augmentation:\n    train_data_gen = ImageDataGenerator(rotation_range=20,\n                                        #width_shift_range=0.2,\n                                        height_shift_range=0.2,\n                                        horizontal_flip=True,\n                                        #vertical_flip=True,\n                                        fill_mode='constant',\n                                        cval=0,\n                                        rescale=1./255)\n    valid_data_gen = ImageDataGenerator(rescale=1./255)\nelse:\n    valid_data_gen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create generators to read images from dataset directory\n# -------------------------------------------------------\n\n# Batch size\nbs = 10 \n\n# img shape\nimg_h = 256\nimg_w = 256\n\nnum_classes=3\n\ndecide_class_indices = True\nif decide_class_indices:\n    classes = ['NO PERSON',        # 0\n               'ALL THE PEOPLE',   # 1\n               'SOMEONE']          # 2\nelse:\n    classes=None\n\n# Training\ntrain_gen = train_data_gen.flow_from_directory(\"./output/train\",\n                                               batch_size=bs,\n                                               classes=classes,\n                                               class_mode='categorical', \n                                               shuffle=True,\n                                               target_size=(img_h,img_w),\n                                               seed=SEED)\n\n# Validation\nvalid_gen = valid_data_gen.flow_from_directory(\"./output/val\",\n                                               batch_size=bs, \n                                               classes=classes,\n                                               class_mode='categorical',\n                                               shuffle=True,\n                                                target_size=(img_h,img_w),\n                                               seed=SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Dataset objects\ntrain_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\ntrain_dataset = train_dataset.repeat()\n\nvalid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\nvalid_dataset = valid_dataset.repeat()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_f = 12 \ndepth = 7\n\nmodel = tf.keras.Sequential()\n\n# Features extraction\nfor i in range(depth):\n\n    if i == 0:\n        input_shape = [img_h, img_w, 3]\n    else:\n        input_shape=[None]\n\n    # Conv block: Conv2D -> Activation -> Pooling\n    model.add(tf.keras.layers.Conv2D(filters=start_f, \n                                     kernel_size=(3, 3), # invece di 3x3\n                                     strides=(1, 1),\n                                     padding='same',\n                                     input_shape=input_shape))\n    model.add(tf.keras.layers.LeakyReLU()) # provo leaky relu e non relu\n    #if i!=(depth-1):\n    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n\n    start_f *= 2\n\n#model.add(tf.keras.layers.GlobalAveragePooling2D())\n\n# Classifier\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(units=512, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(units=512, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\nmodel.add(tf.keras.layers.Dropout(0.3))\n#model.add(tf.keras.layers.Dense(units=512, activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.L2(0.001)))\n#model.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimization params\n# -------------------\n\n# Loss\nloss = tf.keras.losses.CategoricalCrossentropy()\n\n# learning rate\nlr = 1e-4\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n# -------------------\n\n# Validation metrics\n# ------------------\n\nmetrics = ['accuracy']\n# ------------------\n\n# Compile Model\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\n\n\ncwd = os.getcwd()\n\nexps_dir = os.path.join('./', 'classification_experiments')\nif not os.path.exists(exps_dir):\n    os.makedirs(exps_dir)\n\nnow = datetime.now().strftime('%b%d_%H-%M-%S')\n\nmodel_name = 'CNN'\n\nexp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\nif not os.path.exists(exp_dir):\n    os.makedirs(exp_dir)\n    \ncallbacks = []\n\n# Model checkpoint\n# ----------------\nckpt_dir = os.path.join(exp_dir, 'ckpts')\nif not os.path.exists(ckpt_dir):\n    os.makedirs(ckpt_dir)\n\nckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n                                                   save_weights_only=True)  # False to save the model directly\ncallbacks.append(ckpt_callback)\n\n# Visualize Learning on Tensorboard\n# ---------------------------------\ntb_dir = os.path.join(exp_dir, 'tb_logs')\nif not os.path.exists(tb_dir):\n    os.makedirs(tb_dir)\n    \n# By default shows losses and metrics for both training and validation\ntb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n                                             profile_batch=0,\n                                             histogram_freq=1)  # if 1 shows weights histograms\ncallbacks.append(tb_callback)\n\n# Early Stopping\n# --------------\nearly_stop = True\nif early_stop:\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n    callbacks.append(es_callback)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.device('/device:GPU:0')\nhistory = model.fit(x=train_dataset,\n          epochs=100,  \n          steps_per_epoch=len(train_gen),\n          validation_data=valid_dataset,\n          validation_steps=len(valid_gen), \n          callbacks=callbacks)\n\nhistory.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.save_weights(\"./weights_saved/cp_23.ckpt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.load_weights('../classification_experiments/CNN_Nov22_08-59-57/ckpts/cp_37.ckpt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom datetime import datetime\n\ndef create_csv(results, results_dir='/kaggle/working'):\n\n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n\n    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n\n        f.write('Id,Category\\n')\n\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + '\\n')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom PIL import ImageOps\n\ntest_dir = os.path.join(dataset_dir, 'test')\nimage_filenames = next(os.walk(test_dir))[2]\n\nresults = {}\nfor image_name in image_filenames:\n\n    img = Image.open(os.path.join(test_dir, image_name)).convert('RGB') \n   \n    maxsize = (img_h, img_w)\n    img = ImageOps.fit(img, maxsize, Image.ANTIALIAS)\n    img_array = np.array(img)\n    img_array = np.expand_dims(img_array, 0)\n    img_array = img_array/255\n   \n    prediction = np.argmax(model.predict(img_array))   # predicted class\n  \n    results[image_name] = prediction\n\ncreate_csv(results)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}